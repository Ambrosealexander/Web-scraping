{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a38dfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Obtaining dependency information for selenium from https://files.pythonhosted.org/packages/dc/72/96b5afa16908f9abc7c24b70adfd3a46c9740eb728ddfeab28379e38eaf9/selenium-4.16.0-py3-none-any.whl.metadata\n",
      "  Downloading selenium-4.16.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\ansu\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Obtaining dependency information for trio~=0.17 from https://files.pythonhosted.org/packages/39/46/620fbe56f41fa3ccdda2136d947fb9bacce3d1eb163f057f0262a0ddf5e0/trio-0.23.1-py3-none-any.whl.metadata\n",
      "  Downloading trio-0.23.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Obtaining dependency information for trio-websocket~=0.9 from https://files.pythonhosted.org/packages/48/be/a9ae5f50cad5b6f85bd2574c2c923730098530096e170c1ce7452394d7aa/trio_websocket-0.11.1-py3-none-any.whl.metadata\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\ansu\\anaconda3\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\ansu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\ansu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\ansu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Obtaining dependency information for outcome from https://files.pythonhosted.org/packages/55/8b/5ab7257531a5d830fc8000c476e63c935488d74609b50f9384a643ec0a62/outcome-1.3.0.post0-py2.py3-none-any.whl.metadata\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio~=0.17->selenium)\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\ansu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\ansu\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ansu\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "     -------------------------- ----------- 41.0/58.3 kB 991.0 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 58.3/58.3 kB 1.0 MB/s eta 0:00:00\n",
      "Downloading selenium-4.16.0-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/10.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.0 MB 3.7 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.5/10.0 MB 4.3 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.8/10.0 MB 4.8 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.2/10.0 MB 5.9 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.6/10.0 MB 6.2 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.6/10.0 MB 6.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.9/10.0 MB 5.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.4/10.0 MB 6.5 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.5/10.0 MB 5.5 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.8/10.0 MB 5.9 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.0/10.0 MB 5.6 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.7/10.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.2/10.0 MB 6.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.2/10.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.3/10.0 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.7/10.0 MB 6.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.3/10.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.6/10.0 MB 6.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.0/10.0 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.2/10.0 MB 6.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.6/10.0 MB 6.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.8/10.0 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.1/10.0 MB 6.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.5/10.0 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.8/10.0 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.1/10.0 MB 6.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.4/10.0 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.7/10.0 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.0/10.0 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.4/10.0 MB 6.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.6/10.0 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.9/10.0 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.0 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 6.6 MB/s eta 0:00:00\n",
      "Downloading trio-0.23.1-py3-none-any.whl (448 kB)\n",
      "   ---------------------------------------- 0.0/448.3 kB ? eta -:--:--\n",
      "   ------------------------------------- - 430.1/448.3 kB 13.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 448.3/448.3 kB 9.3 MB/s eta 0:00:00\n",
      "Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: sniffio, outcome, h11, wsproto, trio, trio-websocket, selenium\n",
      "  Attempting uninstall: sniffio\n",
      "    Found existing installation: sniffio 1.2.0\n",
      "    Uninstalling sniffio-1.2.0:\n",
      "      Successfully uninstalled sniffio-1.2.0\n",
      "Successfully installed h11-0.14.0 outcome-1.3.0.post0 selenium-4.16.0 sniffio-1.3.0 trio-0.23.1 trio-websocket-0.11.1 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af7616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Start a Chrome WebDriver session\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to Shine.com\n",
    "driver.get(\"https://www.shine.com/\")\n",
    "\n",
    "# Locate the search fields and enter the job title and location\n",
    "job_title = driver.find_element_by_id(\"q\")\n",
    "job_title.send_keys(\"Data Analyst\")\n",
    "\n",
    "location = driver.find_element_by_id(\"l\")\n",
    "location.send_keys(\"Bangalore\")\n",
    "\n",
    "# Click the search button\n",
    "search_button = driver.find_element_by_xpath(\"//button[@data-track='search_jobs']\")\n",
    "search_button.click()\n",
    "\n",
    "# Wait for the job listings to load\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"srlLi\")))\n",
    "\n",
    "# Scraping the data for the first 10 jobs\n",
    "jobs = driver.find_elements_by_class_name(\"srlLi\")[:10]\n",
    "\n",
    "job_data = []\n",
    "for job in jobs:\n",
    "    title = job.find_element_by_class_name(\"job_title\").text\n",
    "    location = job.find_element_by_class_name(\"loc\").text\n",
    "    company_name = job.find_element_by_class_name(\"company_name\").text\n",
    "    experience = job.find_element_by_class_name(\"exp\").text\n",
    "\n",
    "    job_info = {\n",
    "        'Job Title': title,\n",
    "        'Location': location,\n",
    "        'Company Name': company_name,\n",
    "        'Experience Required': experience\n",
    "    }\n",
    "    job_data.append(job_info)\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame(job_data)\n",
    "print(df)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492c13f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638279f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Start a Chrome WebDriver session\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to Shine.com\n",
    "driver.get(\"https://www.shine.com/\")\n",
    "\n",
    "# Locate the search fields and enter the job title and location\n",
    "job_title = driver.find_element_by_id(\"q\")\n",
    "job_title.send_keys(\"Data Scientist\")\n",
    "\n",
    "location = driver.find_element_by_id(\"l\")\n",
    "location.send_keys(\"Bangalore\")\n",
    "\n",
    "# Click the search button\n",
    "search_button = driver.find_element_by_xpath(\"//button[@data-track='search_jobs']\")\n",
    "search_button.click()\n",
    "\n",
    "# Wait for the job listings to load\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"srlLi\")))\n",
    "\n",
    "# Scraping the data for the first 10 jobs\n",
    "jobs = driver.find_elements_by_class_name(\"srlLi\")[:10]\n",
    "\n",
    "job_data = []\n",
    "for job in jobs:\n",
    "    title = job.find_element_by_class_name(\"job_title\").text\n",
    "    location = job.find_element_by_class_name(\"loc\").text\n",
    "    company_name = job.find_element_by_class_name(\"company_name\").text\n",
    "\n",
    "    job_info = {\n",
    "        'Job Title': title,\n",
    "        'Location': location,\n",
    "        'Company Name': company_name,\n",
    "    }\n",
    "    job_data.append(job_info)\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame(job_data)\n",
    "print(df)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172359c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ebf98b91",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WebDriver' object has no attribute 'find_element_by_xpath'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome()\n\u001b[0;32m     11\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.shine.com/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m search_box \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element_by_xpath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//input[@name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m search_box\u001b[38;5;241m.\u001b[39msend_keys(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData Scientist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m search_button \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element_by_xpath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//button[@type=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubmit\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'WebDriver' object has no attribute 'find_element_by_xpath'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://www.shine.com/\")\n",
    "\n",
    "search_box = driver.find_element_by_xpath('//input[@name=\"q\"]')\n",
    "search_box.send_keys(\"Data Scientist\")\n",
    "\n",
    "search_button = driver.find_element_by_xpath('//button[@type=\"submit\"]')\n",
    "search_button.click()\n",
    "\n",
    "search_results = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_all_elements_located((By.XPATH, '//div[@class=\"job-card\"]'))\n",
    ")\n",
    "\n",
    "jobs = [job.find_element_by_xpath('./div[@class=\"job-card\"]') for job in search_results]\n",
    "\n",
    "job_details = [[job.find_element_by_xpath('./h2[@class=\"job-title\"]').text,\n",
    "              job.find_element_by_xpath('./p[@class=\"location\"]').text,\n",
    "              job.find_element_by_xpath('./p[@class=\"company\"]').text,\n",
    "              job.find_element_by_xpath('./p[@class=\"experience\"]').text] for job in jobs]\n",
    "\n",
    "df = pd.DataFrame(job_details, columns=['Job Title', 'Location', 'Company Name', 'Experience Required'])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80259d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a060c4b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WebDriver' object has no attribute 'find_element_by_xpath'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome()\n\u001b[0;32m     11\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.flipkart.com/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m search_box \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element_by_xpath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//input[@name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m search_box\u001b[38;5;241m.\u001b[39msend_keys(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msunglasses\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m search_box\u001b[38;5;241m.\u001b[39msend_keys(Keys\u001b[38;5;241m.\u001b[39mRETURN)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'WebDriver' object has no attribute 'find_element_by_xpath'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "\n",
    "search_box = driver.find_element_by_xpath('//input[@name=\"q\"]')\n",
    "search_box.send_keys(\"sunglasses\")\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "search_results = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_all_elements_located((By.XPATH, '//div[contains(@class, \"_1JM7\")]'))\n",
    ")\n",
    "\n",
    "sunglasses_listings = [driver.find_element_by_xpath('//div[contains(@class, \"_1JM7\")]')]\n",
    "\n",
    "scraped_data = []\n",
    "\n",
    "for listing in sunglasses_listings:\n",
    "    brand = listing.find_element_by_xpath('//span[contains(@class, \"_2IYu\")]').text\n",
    "    product_description = listing.find_element_by_xpath('//div[contains(@class, \"_2IYu\")]').text\n",
    "    price = listing.find_element_by_xpath('//span[contains(@class, \"_3q7p\")]').text\n",
    "\n",
    "    scraped_data.append({\n",
    "        \"Brand\": brand,\n",
    "        \"Product Description\": product_description,\n",
    "        \"Price\": price\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(scraped_data)\n",
    "\n",
    "print(df)\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2db4d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "24f81169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Initialize Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb/productreviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART')\n",
    "\n",
    "# Scraping data for the first 100 reviews\n",
    "reviews_data = []\n",
    "count = 0\n",
    "while count < 100:\n",
    "    time.sleep(3)  # Adding a delay to ensure page loads properly\n",
    "    review_cards = driver.find_elements(By.XPATH, '//div[@class=\"_27M-vq\"]')\n",
    "    for review_card in review_cards:\n",
    "        rating = review_card.find_element(By.XPATH, './/div[@class=\"_3LWZlK _1BLPMq\"]').text\n",
    "        summary = review_card.find_element(By.XPATH, './/p[@class=\"_2-N8zT\"]').text\n",
    "        full_review = review_card.find_element(By.XPATH, './/div[@class=\"t-ZTKy\"]').text\n",
    "        \n",
    "        reviews_data.append({\n",
    "            'Rating': rating,\n",
    "            'Review Summary': summary,\n",
    "            'Full Review': full_review\n",
    "        })\n",
    "        count += 1\n",
    "        if count == 100:\n",
    "            break\n",
    "    \n",
    "    # Clicking on the next page button\n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH, '//a[@class=\"_1LKTO3\"]//span[contains(text(), \"Next\")]')\n",
    "        next_button.click()\n",
    "    except:\n",
    "        break\n",
    "\n",
    "# Creating a DataFrame of the scraped data\n",
    "df = pd.DataFrame(reviews_data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4bf3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "068f3884",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchDriverException",
     "evalue": "Message: Unable to locate or obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchDriverException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Start a new Chrome session\u001b[39;00m\n\u001b[0;32m      9\u001b[0m service \u001b[38;5;241m=\u001b[39m Service(webdriver_path)\n\u001b[1;32m---> 10\u001b[0m driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome(service\u001b[38;5;241m=\u001b[39mservice)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Open Flipkart and search for sneakers\u001b[39;00m\n\u001b[0;32m     13\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.flipkart.com/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py:45\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[1;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[0;32m     42\u001b[0m service \u001b[38;5;241m=\u001b[39m service \u001b[38;5;28;01mif\u001b[39;00m service \u001b[38;5;28;01melse\u001b[39;00m Service()\n\u001b[0;32m     43\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;28;01melse\u001b[39;00m Options()\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     46\u001b[0m     browser_name\u001b[38;5;241m=\u001b[39mDesiredCapabilities\u001b[38;5;241m.\u001b[39mCHROME[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrowserName\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     47\u001b[0m     vendor_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoog\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     48\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m     49\u001b[0m     service\u001b[38;5;241m=\u001b[39mservice,\n\u001b[0;32m     50\u001b[0m     keep_alive\u001b[38;5;241m=\u001b[39mkeep_alive,\n\u001b[0;32m     51\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\chromium\\webdriver.py:49\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[1;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new WebDriver instance of the ChromiumDriver. Starts the\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03mservice and then creates new WebDriver instance of ChromiumDriver.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m - keep_alive - Whether to configure ChromiumRemoteConnection to use HTTP keep-alive.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice \u001b[38;5;241m=\u001b[39m service\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;241m=\u001b[39m DriverFinder\u001b[38;5;241m.\u001b[39mget_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice, options)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m     52\u001b[0m executor \u001b[38;5;241m=\u001b[39m ChromiumRemoteConnection(\n\u001b[0;32m     53\u001b[0m     remote_server_addr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mservice_url,\n\u001b[0;32m     54\u001b[0m     browser_name\u001b[38;5;241m=\u001b[39mbrowser_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m     ignore_proxy\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39m_ignore_local_proxy,\n\u001b[0;32m     58\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\common\\driver_finder.py:44\u001b[0m, in \u001b[0;36mDriverFinder.get_path\u001b[1;34m(service, options)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoSuchDriverException(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(path)\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoSuchDriverException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to locate or obtain driver for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptions\u001b[38;5;241m.\u001b[39mcapabilities[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrowserName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "\u001b[1;31mNoSuchDriverException\u001b[0m: Message: Unable to locate or obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "# Path to your webdriver executable\n",
    "webdriver_path = '/path/to/chromedriver'\n",
    "\n",
    "# Start a new Chrome session\n",
    "service = Service(webdriver_path)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Flipkart and search for sneakers\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "search_bar = driver.find_element(By.NAME, \"q\")\n",
    "search_bar.send_keys(\"sneakers\")\n",
    "search_bar.submit()\n",
    "\n",
    "# Scroll to load more sneakers (change this based on the website's behavior)\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "driver.implicitly_wait(5)  # Let the page load\n",
    "\n",
    "# Scraping data for the first 100 sneakers\n",
    "sneakers_data = []\n",
    "sneakers_count = 0\n",
    "while sneakers_count < 100:\n",
    "    sneakers = driver.find_elements(By.XPATH, \"//div[@class='_1AtVbE']\")\n",
    "    for sneaker in sneakers:\n",
    "        brand = sneaker.find_element(By.XPATH, \".//div[@class='_2WkVRV']\").text\n",
    "        description = sneaker.find_element(By.XPATH, \".//a[@class='IRpwTa']\").get_attribute(\"title\")\n",
    "        price = sneaker.find_element(By.XPATH, \".//div[@class='_30jeq3']\").text\n",
    "        \n",
    "        sneakers_data.append({\n",
    "            \"Brand\": brand,\n",
    "            \"ProductDescription\": description,\n",
    "            \"Price\": price\n",
    "        })\n",
    "        sneakers_count += 1\n",
    "        if sneakers_count >= 100:\n",
    "            break\n",
    "\n",
    "    if sneakers_count < 100:\n",
    "        # If there are more sneakers, scroll further\n",
    "        driver.execute_script(\"window.scrollBy(0, 500);\")\n",
    "        driver.implicitly_wait(3)\n",
    "\n",
    "# Close the browser session\n",
    "driver.quit()\n",
    "\n",
    "# Display the scraped data\n",
    "for idx, sneaker in enumerate(sneakers_data, start=1):\n",
    "    print(f\"Sneaker {idx}:\")\n",
    "    print(sneaker)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa518c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "76a4692c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "WebDriver.__init__() got an unexpected keyword argument 'executable_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[103], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msupport\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m expected_conditions \u001b[38;5;28;01mas\u001b[39;00m EC\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Start a new Chrome session\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome(executable_path\u001b[38;5;241m=\u001b[39mwebdriver_path)\n\u001b[0;32m      9\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.amazon.in/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Find the search bar, enter 'Laptop', and click search\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: WebDriver.__init__() got an unexpected keyword argument 'executable_path'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "# Start a new Chrome session\n",
    "driver = webdriver.Chrome(executable_path=webdriver_path)\n",
    "driver.get(\"https://www.amazon.in/\")\n",
    "\n",
    "# Find the search bar, enter 'Laptop', and click search\n",
    "search_bar = driver.find_element(By.ID, \"twotabsearchtextbox\")\n",
    "search_bar.send_keys(\"Laptop\")\n",
    "search_button = driver.find_element(By.ID, \"nav-search-submit-button\")\n",
    "search_button.click()\n",
    "\n",
    "# Filter by CPU Type \"Intel Core i7\"\n",
    "cpu_filter = driver.find_element(By.XPATH, \"//span[text()='Intel Core i7']\")\n",
    "cpu_filter.click()\n",
    "\n",
    "# Wait for the filter to be applied\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//span[@class='aok-float-left']\")))\n",
    "\n",
    "# Scrape data for the first 10 laptops\n",
    "laptop_data = []\n",
    "laptops = driver.find_elements(By.XPATH, \"//div[@data-component-type='s-search-result']\")\n",
    "for laptop in laptops[:10]:\n",
    "    title = laptop.find_element(By.XPATH, \".//h2/a/span\").text\n",
    "    \n",
    "    try:\n",
    "        rating = laptop.find_element(By.XPATH, \".//span[@class='a-icon-alt']\").get_attribute(\"innerHTML\")\n",
    "    except:\n",
    "        rating = \"Not Rated\"\n",
    "    \n",
    "    try:\n",
    "        price = laptop.find_element(By.XPATH, \".//span[@class='a-price-whole']\").text\n",
    "    except:\n",
    "        price = \"Price not available\"\n",
    "    \n",
    "    laptop_data.append({\n",
    "        \"Title\": title,\n",
    "        \"Ratings\": rating,\n",
    "        \"Price\": price\n",
    "    })\n",
    "\n",
    "# Close the browser session\n",
    "driver.quit()\n",
    "\n",
    "# Display the scraped data\n",
    "for idx, laptop in enumerate(laptop_data, start=1):\n",
    "    print(f\"Laptop {idx}:\")\n",
    "    print(laptop)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df06ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "675f5e62",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchDriverException",
     "evalue": "Message: Unable to locate or obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchDriverException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Start a new Chrome session\u001b[39;00m\n\u001b[0;32m      9\u001b[0m service \u001b[38;5;241m=\u001b[39m Service(webdriver_path)\n\u001b[1;32m---> 10\u001b[0m driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome(service\u001b[38;5;241m=\u001b[39mservice)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Open Flipkart and search for sneakers\u001b[39;00m\n\u001b[0;32m     13\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.flipkart.com/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py:45\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[1;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[0;32m     42\u001b[0m service \u001b[38;5;241m=\u001b[39m service \u001b[38;5;28;01mif\u001b[39;00m service \u001b[38;5;28;01melse\u001b[39;00m Service()\n\u001b[0;32m     43\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;28;01melse\u001b[39;00m Options()\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     46\u001b[0m     browser_name\u001b[38;5;241m=\u001b[39mDesiredCapabilities\u001b[38;5;241m.\u001b[39mCHROME[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrowserName\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     47\u001b[0m     vendor_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoog\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     48\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m     49\u001b[0m     service\u001b[38;5;241m=\u001b[39mservice,\n\u001b[0;32m     50\u001b[0m     keep_alive\u001b[38;5;241m=\u001b[39mkeep_alive,\n\u001b[0;32m     51\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\chromium\\webdriver.py:49\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[1;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new WebDriver instance of the ChromiumDriver. Starts the\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03mservice and then creates new WebDriver instance of ChromiumDriver.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m - keep_alive - Whether to configure ChromiumRemoteConnection to use HTTP keep-alive.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice \u001b[38;5;241m=\u001b[39m service\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;241m=\u001b[39m DriverFinder\u001b[38;5;241m.\u001b[39mget_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice, options)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m     52\u001b[0m executor \u001b[38;5;241m=\u001b[39m ChromiumRemoteConnection(\n\u001b[0;32m     53\u001b[0m     remote_server_addr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mservice_url,\n\u001b[0;32m     54\u001b[0m     browser_name\u001b[38;5;241m=\u001b[39mbrowser_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m     ignore_proxy\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39m_ignore_local_proxy,\n\u001b[0;32m     58\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\common\\driver_finder.py:44\u001b[0m, in \u001b[0;36mDriverFinder.get_path\u001b[1;34m(service, options)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoSuchDriverException(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(path)\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoSuchDriverException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to locate or obtain driver for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptions\u001b[38;5;241m.\u001b[39mcapabilities[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrowserName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "\u001b[1;31mNoSuchDriverException\u001b[0m: Message: Unable to locate or obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "# Path to your webdriver executable\n",
    "webdriver_path = '/path/to/chromedriver'\n",
    "\n",
    "# Start a new Chrome session\n",
    "service = Service(webdriver_path)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Flipkart and search for sneakers\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "search_bar = driver.find_element(By.NAME, \"q\")\n",
    "search_bar.send_keys(\"sneakers\")\n",
    "search_bar.submit()\n",
    "\n",
    "# Scroll to load more sneakers (change this based on the website's behavior)\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "driver.implicitly_wait(5)  # Let the page load\n",
    "\n",
    "# Scraping data for the first 100 sneakers\n",
    "sneakers_data = []\n",
    "sneakers_count = 0\n",
    "while sneakers_count < 100:\n",
    "    sneakers = driver.find_elements(By.XPATH, \"//div[@class='_1AtVbE']\")\n",
    "    for sneaker in sneakers:\n",
    "        brand = sneaker.find_element(By.XPATH, \".//div[@class='_2WkVRV']\").text\n",
    "        description = sneaker.find_element(By.XPATH, \".//a[@class='IRpwTa']\").get_attribute(\"title\")\n",
    "        price = sneaker.find_element(By.XPATH, \".//div[@class='_30jeq3']\").text\n",
    "        \n",
    "        sneakers_data.append({\n",
    "            \"Brand\": brand,\n",
    "            \"ProductDescription\": description,\n",
    "            \"Price\": price\n",
    "        })\n",
    "        sneakers_count += 1\n",
    "        if sneakers_count >= 100:\n",
    "            break\n",
    "\n",
    "    if sneakers_count < 100:\n",
    "        # If there are more sneakers, scroll further\n",
    "        driver.execute_script(\"window.scrollBy(0, 500);\")\n",
    "        driver.implicitly_wait(3)\n",
    "\n",
    "# Close the browser session\n",
    "driver.quit()\n",
    "\n",
    "# Display the scraped data\n",
    "for idx, sneaker in enumerate(sneakers_data, start=1):\n",
    "    print(f\"Sneaker {idx}:\")\n",
    "    print(sneaker)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b473ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d861b770",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WebDriver' object has no attribute 'find_element_by_link_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.jagranjosh.com/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Step 2: Click on the GK option\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m driver\u001b[38;5;241m.\u001b[39mfind_element_by_link_text(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mclick()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Step 3: Click on the List of all Prime Ministers of India\u001b[39;00m\n\u001b[0;32m     12\u001b[0m driver\u001b[38;5;241m.\u001b[39mfind_element_by_link_text(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mList of all Prime Ministers of India\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mclick()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'WebDriver' object has no attribute 'find_element_by_link_text'"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Open the webpage\n",
    "driver = selenium.webdriver.Chrome()\n",
    "driver.get(\"https://www.jagranjosh.com/\")\n",
    "\n",
    "# Step 2: Click on the GK option\n",
    "driver.find_element_by_link_text(\"GK\").click()\n",
    "\n",
    "# Step 3: Click on the List of all Prime Ministers of India\n",
    "driver.find_element_by_link_text(\"List of all Prime Ministers of India\").click()\n",
    "\n",
    "# Step 4: Scrape the data\n",
    "pm_data = []\n",
    "for pm in driver.find_elements_by_class_name(\"pm-list\"):\n",
    "    name = pm.find_element_by_class_name(\"pm-name\").text.strip()\n",
    "    born_dead = pm.find_element_by_class_name(\"pm-born-dead\").text.strip()\n",
    "    term_of_office = pm.find_element_by_class_name(\"pm-term-of-office\").text.strip()\n",
    "    remarks = pm.find_element_by_class_name(\"pm-remarks\").text.strip()\n",
    "    pm_data.append({\"Name\": name, \"Born-Dead\": born_dead, \"Term of office\": term_of_office, \"Remarks\": remarks})\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "pm_df = pd.DataFrame(pm_data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(pm_df)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0243088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cc234f82",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WebDriver' object has no attribute 'find_element_by_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.motor1.com/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Type in the search bar and click search\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m search_bar \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element_by_name(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m search_bar\u001b[38;5;241m.\u001b[39msend_keys(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m50 most expensive cars\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m search_bar\u001b[38;5;241m.\u001b[39msubmit()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'WebDriver' object has no attribute 'find_element_by_name'"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Set up the webdriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to the Motor1 website\n",
    "driver.get(\"https://www.motor1.com/\")\n",
    "\n",
    "# Type in the search bar and click search\n",
    "search_bar = driver.find_element_by_name(\"q\")\n",
    "search_bar.send_keys(\"50 most expensive cars\")\n",
    "search_bar.submit()\n",
    "\n",
    "# Wait for the search results page to load\n",
    "wait = WebDriverWait(driver, 10)\n",
    "wait.until(EC.presence_of_element_located((By.XPATH, \"//div[contains(@class, 'search-results')]\")))\n",
    "\n",
    "# Extract the list of cars from the search results page\n",
    "cars = []\n",
    "for car in driver.find_elements_by_xpath(\"//div[contains(@class, 'search-results')]//li\"):\n",
    "    car_name = car.find_element_by_xpath(\".//a[contains(@href, 'car-')]\").text\n",
    "    car_price = car.find_element_by_xpath(\".//span[contains(@class, 'price')]\").text\n",
    "    cars.append({\"\": car_name, \"Price\": car_price})\n",
    "\n",
    "# Create a pandas dataframe from the list of cars\n",
    "df = pd.DataFrame(cars)\n",
    "\n",
    "# Print the dataframe\n",
    "print(df)\n",
    "\n",
    "# Close the webdriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0fff0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
